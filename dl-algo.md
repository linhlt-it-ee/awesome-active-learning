## 2022
##### ICML, Sequentail Covariate Shift Dection Using Classifier Two-Sample Tests
##### ICLR, PICO: Contrastive Label Disambiguation for partial label learning
##### CVPR, PNP: Robust Learning from Noisy Labels by Probabilistic Noise Prediction
## 2021
##### A survey of label-noise Representation learning: Past, Present and Future
##### CVPR, Improving Unsupervised Image Clustering With Robust Learning
##### ICML, Confidence scores make instance-dependent Label-noise learning possible
##### CVPR, Jo-SRC: A contrastive approach for combating noisy labels
##### Vitaly Feldman, Does Learning require memorization? A short tale about long tail
## 2020
##### NIPS, What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation: estimate closely-related sampled influence and memorization through long-tailed distribution
##### NIPS, A topological Filter for Learning with Label Noise: detect clean data with high probability
##### SIGUA: Forgetting May make learning with noisy labels more robust: self-teaching + backward correction
## 2019
##### ICLR, Multi-classs classification without multi-class labels
##### WSDM, Spring- Electrical models for link prediction
##### ICML, Unsupervised Label Noise Modeling and Loss correction: lipschitz and generalization bound
## 2018
##### NIPS, Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels
##### ICML, Dimensionality-Driven learning with noisy labels, (need to read again for constructing images)
## 2017
##### ICLR, Understanding deep learning requires rethinking generalization (Google brain)
## 2010 
##### Unsupervised Feature Selection for Multi-Cluster Data: good example of the time with Laplace and Clustering  using L1, eigen
Vitaly Feldman, Harvard, Optimal Hardness Results for Maximizing Agreements with Monomials
